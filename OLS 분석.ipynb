{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "OLS Summary Result 분석 \n",
    "## Interpreting OLS results\n",
    "\n",
    "OLS 에는 하기와 같이 분석항목이 들어가있다\n",
    "\n",
    "1. Model Performance (모델 측정) - Multiple R-Squared & Adjusted R-Squared \n",
    "2. each explanotory variable (각각의 설명변수) - Variable, Coef ,Std Error, T-Statistic, Prob(T-Statistic)\n",
    "3. model significance 모델 중요성 - F-Statistic, Prob(F-Statistic)\n",
    "4. stationarity (안정성) Koenker Statistic\n",
    "5. model bias 모델 편향 정도 - Jarque-Bera Statistic\n",
    "6. spatial autocorrelation 평가 - OLS 결과에대한 신뢰도를 나타냄, 중요 데이터가 빠졌는지확인, 모델을 믿을수 있는지 확인 (만약 높거나 낮은 잔차가 너무 많으면 중요데이터가 빠졌음: misspecification)  \n",
    "\n",
    "#### Result Summary\n",
    "  - Dep.Variable : 종속변수, 보스턴집값에서는 집값 실제 가격들을 의미한다\n",
    "  - No.Observations : 데이터 개수\n",
    "  - Df Residuals: 잔차 자유도, The residual degree of freedom, defined as the number of observations minus the rank of the regressor matrix.\n",
    "  - Df Model: 모형 자유도, The Model degeree of freedom, definded as the rank of the regressor of matrix minus 1 if a constant is included.(선형회귀 행렬, 상수항 회귀계수가 포함되어있을경우  W hat 행렬 -1 에서 독립 열랭크개수)  \n",
    "  - Multiple R-Squared & Adjusted R-Squared values : 모델 퍼포먼스의 측정치이다 둘다 0과 1사이의 범위값을 갖는다. 여기서 0.741 이라면 이 모델이 74퍼센트정도로 종속변수 변화를 설명한다고 볼 수 있다. Adjusted는 R-Squared 보다 작은 값을 가지며 모델의 복잡도(변수의 수)를 반영하기 때문에 더 정확한 값을 나타낸다.\n",
    "  - Coefficient : 가중치 벡터 w의 계수들, 각각의 feature 변수의 가중치를 나타낸다. 즉 영향도를 나타낸다. (기울기로도 나타낼수 있다.)\n",
    "  - Const: y 절편 (상수항)\n",
    "  - std err : Estimated 가중치 벡터 w hat의 모형계수 표준편차\n",
    " \n",
    " \n",
    " \n",
    "#### OLS Diagnostics \n",
    "\n",
    "  - T-검정: 단일계수 t검정의 검정통계량, 귀무가설 H0:wi=0 : 특정회귀계수 wi 가 0이다라고 가정, 즉 단일 회귀계수가 독립변수와 종속변수에 영향을 미치는지를 확인, 만약 0이라면(귀무가설채택) 해당독립변수는 종속변수와 아무런상관이 없음  \n",
    "      - P >|T|: 귀무가설 H0:wi=0 에 대한 유의 확률, p-value가 낮으면 귀무가설  H0:wi=0이다 라는 가설이 먹히지 않음\n",
    "  - 회귀분석 F-검정(Loss-of-fit 검정):전체회귀계수에 대한 검정통계랑: 귀무가설 H0:w1=w2=⋯=wK=0 , 즉 전체회귀계수가 0이다(독립변수와 종속변수간에 상관관계가 없다); 전체 독립변수 중 어느것도 의미를 가진것이 없다는 뜻.\n",
    "      - Prob(F-statistc): 귀무가설 H0:w1=w2=⋯=wK=0 에 대한 유의 확률, p-value 이 많이 작으면 귀무가설 기각이므로 전체 독립변수들이 더 강력하게 모형에 영향을 미친다는것을 알 수 있다.\n",
    "  - Omnibus: 정규성검정\n",
    "  - Jarque-Bera Statistic : 잔차 Residuals (y-y^) 가 정규 분포를 따르는지 확인\n",
    "  - Prob(Omnibus): 정규성검정에 대한 유의확률\n",
    "  - Skew: 3차 모멘토: 찌그러짐 정도, 0에 가까울수록 대칭인 정규분포를 따른다, 양수면 오른쪽으로 치우침\n",
    "  - Kurtosis : 4차 모멘토: 확률분포가 중앙으로 얼마나 몰려있는지 보여줌, 2~3 근처에 있어야 한다.\n",
    "  - Cond. No.: 독립변수들의 컨디션,1이어야하며 1보다 커지면 독립변수들중에 상관관계가 종속관계에 있는경우, 스케일링이 잘못된 경우가 있는 것.\n",
    " \n",
    "  http://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html\n",
    "  http://resources.esri.com/help/9.3/arcgisengine/java/gp_toolref/spatial_statistics_tools/interpreting_ols_results.htm\n",
    "    \n",
    "\n",
    "\n",
    "[4:24] \n",
    "공유드려요~ 혹시 틀린부분 있으면 말씀주세요~ 저도 공부하는중이라 틀릴수도 있어요\n",
    "\n",
    "이상협_A [4:39 PM] \n",
    "datascienceschool.net에 skewness, 왜도가 양수면 오른쪽으로 치우친다고 되어있습니다. 그런데 스큐니스가 양수값이면 긴 꼬리 부분이 오른쪽으로 나와있는 것을 의미합니다. 그러니까 스큐니스가 양수면 값이 왼쪽으로 몰린 모형이 나오게 됩니다.ㅎㅎ(중앙값이 평균보다 큰 경우이므로)\n",
    "http://blog.naver.com/PostView.nhn?blogId=istech7&logNo=50154573592"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
